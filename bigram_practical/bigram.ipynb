{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c11f74d-4598-425f-8ea4-4ccf7423601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"are you still here ?\",\n",
    "\"where are you ?\",\n",
    "\"are you tired ?\",\n",
    "\"i am tired .\",\n",
    "\"are you in england ?\",\n",
    "\"were you in mexico ?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea82b03-b575-4fb1-a0cb-8bc6f66c1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are you still here ?',\n",
       " 'where are you ?',\n",
       " 'are you tired ?',\n",
       " 'i am tired .',\n",
       " 'are you in england ?',\n",
       " 'were you in mexico ?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613e62fa-d4a7-4e83-b092-8e9ba9fea13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = {}\n",
    "total_words = 0\n",
    "for sentence in corpus:\n",
    "    sentence = '<BOS> ' + sentence\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word not in unigrams:\n",
    "            unigrams[word] = 1\n",
    "        else:\n",
    "            unigrams[word]+=1\n",
    "        total_words +=1\n",
    "        \n",
    "# prob_values = {}\n",
    "# for word in unigrams:\n",
    "#     prob_values[word] = unigrams[word]/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32895f5a-0c95-402c-8910-9772292db320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<BOS>': 6,\n",
       " 'are': 4,\n",
       " 'you': 5,\n",
       " 'still': 1,\n",
       " 'here': 1,\n",
       " '?': 5,\n",
       " 'where': 1,\n",
       " 'tired': 2,\n",
       " 'i': 1,\n",
       " 'am': 1,\n",
       " '.': 1,\n",
       " 'in': 2,\n",
       " 'england': 1,\n",
       " 'were': 1,\n",
       " 'mexico': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3326b174-6226-4f17-81c4-ee26cb653702",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = {}\n",
    "total_words = 0\n",
    "for sentence in corpus:\n",
    "    sentence = '<BOS> ' + sentence\n",
    "    words = sentence.split(\" \")\n",
    "    for i in range(len(words)):\n",
    "        if i+1 < len(sentence.split(\" \")):\n",
    "            if (words[i], words[i+1]) not in bigrams:\n",
    "                bigrams[(words[i], words[i+1])] = 1\n",
    "            else:\n",
    "                bigrams[(words[i], words[i+1])]+=1\n",
    "            total_words +=1\n",
    "        \n",
    "# bi_prob_values = {}\n",
    "# for word in bigrams:\n",
    "#     bi_prob_values[word] = bigrams[word]/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a70bcb7-f579-4460-86d2-cd665eccf8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<BOS>', 'are'): 3,\n",
       " ('are', 'you'): 4,\n",
       " ('you', 'still'): 1,\n",
       " ('still', 'here'): 1,\n",
       " ('here', '?'): 1,\n",
       " ('<BOS>', 'where'): 1,\n",
       " ('where', 'are'): 1,\n",
       " ('you', '?'): 1,\n",
       " ('you', 'tired'): 1,\n",
       " ('tired', '?'): 1,\n",
       " ('<BOS>', 'i'): 1,\n",
       " ('i', 'am'): 1,\n",
       " ('am', 'tired'): 1,\n",
       " ('tired', '.'): 1,\n",
       " ('you', 'in'): 2,\n",
       " ('in', 'england'): 1,\n",
       " ('england', '?'): 1,\n",
       " ('<BOS>', 'were'): 1,\n",
       " ('were', 'you'): 1,\n",
       " ('in', 'mexico'): 1,\n",
       " ('mexico', '?'): 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62228d03-98bc-4b2b-82d4-71b1f8b48d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9baaa7c2-67b6-458b-8f56-e9e3ddfc874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "print()\n",
    "for tokens in bigrams:\n",
    "    if tokens[0] not in model:\n",
    "        model[tokens[0]] = {tokens[1] : bigrams[tokens]/unigrams[tokens[0]]}\n",
    "    else:\n",
    "        model[tokens[0]][tokens[1]] = bigrams[tokens]/unigrams[tokens[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e90e854-544e-42f6-92f1-be2c6335d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<BOS>': {'are': 0.5,\n",
       "  'where': 0.16666666666666666,\n",
       "  'i': 0.16666666666666666,\n",
       "  'were': 0.16666666666666666},\n",
       " 'are': {'you': 1.0},\n",
       " 'you': {'still': 0.2, '?': 0.2, 'tired': 0.2, 'in': 0.4},\n",
       " 'still': {'here': 1.0},\n",
       " 'here': {'?': 1.0},\n",
       " 'where': {'are': 1.0},\n",
       " 'tired': {'?': 0.5, '.': 0.5},\n",
       " 'i': {'am': 1.0},\n",
       " 'am': {'tired': 1.0},\n",
       " 'in': {'england': 0.5, 'mexico': 0.5},\n",
       " 'england': {'?': 1.0},\n",
       " 'were': {'you': 1.0},\n",
       " 'mexico': {'?': 1.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524a683a-80dc-4ee5-abf8-a8ee4f15f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 0.006400000000000002 ['<BOS>', 'where', 'are', 'you', '?']\n",
    "\n",
    "predict = [\"were you in england ?\"]\n",
    "probability = 1\n",
    "for sentence in predict:\n",
    "    sentence = '<BOS> ' + sentence\n",
    "    words = sentence.split(\" \")\n",
    "    for i in range(len(words)):\n",
    "        if i+1 < len(sentence.split(\" \")):\n",
    "            probability *=model[words[i]][words[i+1]]\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e829533f-5554-4168-9643-f306a7e3cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<BOS> where are you ?', 0.03333333333333333), ('<BOS> were you in england ?', 0.03333333333333333), ('<BOS> are you in mexico ?', 0.1)]\n"
     ]
    }
   ],
   "source": [
    "# 0.006400000000000002 ['<BOS>', 'where', 'are', 'you', '?']\n",
    "\n",
    "predict = [\"where are you ?\", \"were you in england ?\", \"are you in mexico ?\"]\n",
    "\n",
    "results = []\n",
    "for sentence in predict:\n",
    "    probability = 1\n",
    "    sentence = '<BOS> ' + sentence\n",
    "    words = sentence.split(\" \")\n",
    "    for i in range(len(words)):\n",
    "        if i+1 < len(sentence.split(\" \")):\n",
    "            probability *=model[words[i]][words[i+1]]\n",
    "    results.append((sentence, probability))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "739d81fc-0a2f-4a7f-b703-8c629f3641ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 bigrams.\n",
      "defaultdict(<function <lambda> at 0x1031c44c0>, {'<BOS>': defaultdict(<class 'float'>, {'are': 0.5, 'where': 0.16666666666666666, 'i': 0.16666666666666666, 'were': 0.16666666666666666}), 'are': defaultdict(<class 'float'>, {'you': 1.0}), 'you': defaultdict(<class 'float'>, {'still': 0.2, '?': 0.2, 'tired': 0.2, 'in': 0.4}), 'still': defaultdict(<class 'float'>, {'here': 1.0}), 'here': defaultdict(<class 'float'>, {'?': 1.0}), '?': defaultdict(<class 'float'>, {'': 1.0}), 'where': defaultdict(<class 'float'>, {'are': 1.0}), 'tired': defaultdict(<class 'float'>, {'?': 0.5, '.': 0.5}), 'i': defaultdict(<class 'float'>, {'am': 1.0}), 'am': defaultdict(<class 'float'>, {'tired': 1.0}), '.': defaultdict(<class 'float'>, {'': 1.0}), 'in': defaultdict(<class 'float'>, {'england': 0.5, 'mexico': 0.5}), 'england': defaultdict(<class 'float'>, {'?': 1.0}), 'were': defaultdict(<class 'float'>, {'you': 1.0}), 'mexico': defaultdict(<class 'float'>, {'?': 1.0})})\n"
     ]
    }
   ],
   "source": [
    "# import sys, math, re, pickle\n",
    "# from collections import defaultdict, Counter\n",
    "\n",
    "# def tokenise(s):\n",
    "#     \"\"\"Tokenise a line\"\"\"\n",
    "#     o = re.sub('([^a-zA-Z0-9\\']+)', ' \\g<1> ', s.strip())\n",
    "#     return re.sub('  *', ' ', o).split(' ')\n",
    "\n",
    "# model = defaultdict(lambda : defaultdict(float)) \n",
    "\n",
    "# bigrams, unigrams = defaultdict(Counter), Counter() # Unigram and bigram counts \n",
    "\n",
    "# corpus = [\"are you still here ?\",\n",
    "# \"where are you ?\",\n",
    "# \"are you tired ?\",\n",
    "# \"i am tired .\",\n",
    "# \"are you in england ?\",\n",
    "# \"were you in mexico ?\"]\n",
    "\n",
    "# for line in corpus: # Collect counts from standard input\n",
    "#     tokens = ['<BOS>'] + tokenise(line)\n",
    "#     for i in range(len(tokens) - 1):\n",
    "#         bigrams[tokens[i]][tokens[i+1]] += 1\n",
    "#         unigrams[tokens[i]] += 1\n",
    "# #     line = sys.stdin.readline()\n",
    "\n",
    "# for i in bigrams: # Calculate probabilities\n",
    "#     for j in bigrams[i]:\n",
    "#         model[i][j] = bigrams[i][j] / unigrams[i]\n",
    "\n",
    "# print('Saved %d bigrams.' % sum([len(i) for i in model.items()]))\n",
    "# pickle.dump(dict(model), open('model.lm', 'wb'))\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543012a-0435-488e-81b6-090e2b95f20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
